{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Locate Sources with Array of Arrays\n",
    "<img src=\"pictures/Grenzgletscher25_oben.jpg\" alt=\"Grenzgletscher 25\" width=\"600\"/> <img src=\"pictures/Search_2025.jpg\" alt=\"Grenzgletscher 25\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Azimuth Estimation Using fk-Analysis \n",
    " by J. Wassermann \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "%matplotlib inline \n",
    "\n",
    "#import matplotlib\n",
    "from obspy import *\n",
    "from obspy.core import AttribDict\n",
    "from obspy.core.inventory.inventory import Inventory\n",
    "from obspy.clients.filesystem import sds\n",
    "from obspy.clients.fdsn import Client\n",
    "import obspy_arraytools as AA\n",
    "import obspy.signal.util as util\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "SDS_DATA_PATH = \"/Users/jowa/Skience2026_Data/data_sds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(par):\n",
    "    client = sds.Client(sds_root = par.sds_root)\n",
    "    fp=open(par.phasefile,\"r\")\n",
    "    while 1:\n",
    "        line = fp.readline()\n",
    "        if not line: break\n",
    "        data = line.split(',')\n",
    "        #we add tt_min and tt_max to be sure that the data frame is large enough\n",
    "        if data[1] == \"short_signal\\n\" or data[1] == \"icequake\\n\":\n",
    "            start = UTCDateTime(data[0])-par.pre_trigger      \n",
    "            end = start + par.w_mig #UTCDateTime(data[1]) \n",
    "        try:\n",
    "            for arraystats in par.arrays:\n",
    "                sz = Stream()\n",
    "                inv= Inventory()\n",
    "                i = 0\n",
    "                #reading in data and metadata of the array(s)\n",
    "                for station in arraystats:\n",
    "                    net,stat,loc,chan=station.split('.')\n",
    "                    try:\n",
    "                        tr = client.get_waveforms(network=net,station=stat,location=loc,channel=chan, starttime=start, endtime=end)\n",
    "                        ii = read_inventory(\"./stationxml/station_%s_%s.xml\"%(net,stat))\n",
    "                        tr.merge()\n",
    "                        if tr[0].stats.endtime < end or tr[0].stats.starttime > start:\n",
    "                            print(\"trace \",tr, \"too short\")\n",
    "                        else: \n",
    "                            sz += tr\n",
    "                            inv += ii\n",
    "                    except:\n",
    "                        print(\"%s not loaded ...\",station)\n",
    "                        pass\n",
    "                \n",
    "                sz.merge()\n",
    "                print(sz)\n",
    "                sz.detrend(\"linear\")\n",
    "                sz.attach_response(inv)\n",
    "        \n",
    "                #we restrict ourself to the vertical components.... at least for now\n",
    "                vc = sz.select(component=\"Z\")\n",
    "        \n",
    "                #veeeery convenient function \n",
    "                # handles all geometry issues of the array\n",
    "                grenz = AA.SeismicArray(\"\",inv)\n",
    "                grenz.inventory_cull(vc)\n",
    "        \n",
    "                print(\"Center of gravity: \",grenz.center_of_gravity)\n",
    "                outray = 0.\n",
    "                #we use here a covariance based FK-analysis\n",
    "                outray = grenz.fk_analysis(vc, frqlow=par.fl, frqhigh=par.fh, prefilter=True,\\\n",
    "                         static3d=False, array_response=False,vel_corr=4.8, wlen=par.win_len,\\\n",
    "                         wfrac=par.win_frac,sec_km=True,\n",
    "                         slx=(par.sll_x,par.slm_x),sly=(par.sll_y,par.slm_y),\n",
    "                         sls=par.sl_s)      \n",
    "            \n",
    "                res = [outray.win_starttimes,outray.max_rel_power,outray.max_abs_power,outray.max_pow_baz,outray.max_pow_slow]\n",
    "                res = np.asarray(res)\n",
    "                net,stat,_,_ = arraystats[0].split(\".\")\n",
    "                # save the output as csv file\n",
    "                outfile = \"%s/ARY-%s_%s-%s.csv\"%(par.output_path,start,net,stat[:-2])\n",
    "                with open(outfile, 'w', newline='') as csvfile:\n",
    "                    writer = csv.writer(csvfile, dialect='unix')\n",
    "                    writer.writerows(res.T)\n",
    "\n",
    "    #############################################\n",
    "    # Plotting .....\n",
    "    #############################################\n",
    "\n",
    "                hist_baz, bins_baz = np.histogram(outray.max_pow_baz, bins=int(360/2), \\\n",
    "                                    range = (0,360), weights = outray.max_rel_power, density = False)\n",
    "                max_baz =  np.argmax(hist_baz)\n",
    "                print(bins_baz[max_baz])\n",
    "\n",
    "                xlocator = mdates.AutoDateLocator()\n",
    "\n",
    "                fig = plt.figure()\n",
    "                axbaz = fig.add_subplot(212)\n",
    "                axtrace = fig.add_subplot(211,sharex=axbaz)\n",
    "           \n",
    "                axtrace.plot(vc[0].times(\"matplotlib\"),vc[0].data,'k')\n",
    "                axtrace.ticklabel_format(axis='y', style='sci', scilimits=(-2,2))\n",
    "                axtrace.tick_params( axis='x',labelbottom='off')\n",
    "                axtrace.set_ylabel('[a.u.]',color='k')\n",
    "                for tl in axtrace.get_yticklabels():\n",
    "                    tl.set_color('k')\n",
    "            \n",
    "                npts = vc[0].stats.npts\n",
    "                nsamp = int(par.win_len*vc[0].stats.sampling_rate)\n",
    "                axtrace.axvline(vc[0].times(\"matplotlib\")[int(npts/6)], ls = \"--\",color=\"g\")\n",
    "                axtrace.axvline(vc[0].times(\"matplotlib\")[int(npts/6)+nsamp], ls = \"--\",color=\"g\")\n",
    "                timeb = [number.matplotlib_date for number in outray.win_starttimes]\n",
    "                axbaz.scatter(timeb, outray.max_pow_baz,c=outray.max_rel_power,cmap='Reds',s=15)\n",
    "                axbaz.set_ylabel('[deg]')\n",
    "                axbaz.set_ylim(0,360)\n",
    "            \n",
    "                axbaz.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "                axbaz.xaxis.set_major_locator(xlocator)\n",
    "\n",
    "                fig.autofmt_xdate()\n",
    "                \n",
    "                plt.savefig(\"%s/ARRAY_%s-%s_%s.png\"%(par.figure_path,net,stat[:-2],start))\n",
    "                #plt.show()\n",
    "        \n",
    "                phi = outray.max_pow_baz*2*np.pi/360\n",
    "                hist_baz, bins_baz = np.histogram(phi, bins=int(360/2),\n",
    "                                                            range = (0,2*np.pi),\n",
    "                                                            weights = outray.max_rel_power,\n",
    "                                                            density = True)\n",
    "\n",
    "                cmap = cm.viridis\n",
    "                bins_number = 180  # the [0, 360) interval will be subdivided into this\n",
    "                            # number of equal bins\n",
    "                bins = np.linspace(0.0, 2 * np.pi, bins_number + 1)\n",
    "                angles = 2 * np.pi * phi/360.\n",
    "\n",
    "                width = 2 * np.pi / bins_number\n",
    "                ax = plt.subplot(1, 1, 1, projection='polar')\n",
    "                ax.set_theta_zero_location(\"N\")\n",
    "                ax.set_theta_direction(-1)\n",
    "                ax.set_yticklabels([])\n",
    "            \n",
    "                bars = ax.bar(bins_baz[:-1], hist_baz, width=width,bottom=0.0,alpha=.7,color=\"orange\")\n",
    "                plt.savefig(\"%s/ROSE_%s-%s_%s.png\"%(par.figure_path,net,stat[:-2],start),dpi = 72)\n",
    "               # plt.show()\n",
    "                plt.close(\"all\")\n",
    "        except:\n",
    "            print(\"Didn't work \\n\")\n",
    "            pass\n",
    "            \n",
    "                                                                                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = AttribDict()\n",
    "par.arrays = [[\"4D.A1P1.SW.GPZ\",\"4D.A1P2.SW.GPZ\",\"4D.A1P3.SW.GPZ\",\"4D.A1P4.SW.GPZ\",\\\n",
    "              \"4D.A1P5.SW.GPZ\",\"4D.A1P6.SW.GPZ\",\"4D.A1P7.SW.GPZ\",\"4D.A1P8.SW.GPZ\"],\\\n",
    "            [\"4D.A2P1.SW.GPZ\",\"4D.A2P2.SW.GPZ\",\"4D.A2P3.SW.GPZ\",\"4D.A2P4.SW.GPZ\",\\\n",
    "              \"4D.A2P5.SW.GPZ\",\"4D.A2P6.SW.GPZ\",\"4D.A2P7.SW.GPZ\",\"4D.A2P8.SW.GPZ\"],\\\n",
    "            [\"4D.A3P1.SW.GPZ\",\"4D.A3P2.SW.GPZ\",\"4D.A3P3.SW.GPZ\",\"4D.A3P4.SW.GPZ\",\\\n",
    "              \"4D.A3P5.SW.GPZ\",\"4D.A3P6.SW.GPZ\",\"4D.A3P7.SW.GPZ\",\"4D.A3P8.SW.GPZ\"]]\n",
    "print(\"No of arrays to be used: \",len(par.arrays))\n",
    "par.no_arrays = len(par.arrays)\n",
    "\n",
    "par.output_path = \"./Grenzgletscher_fk\"\n",
    "par.figure_path = \"./Grenzgletscher_fk/figure\"\n",
    "\n",
    "par.fl=5.0 #lower frequency \n",
    "par.fh=80.00 #upper frequency limit\n",
    "par.win_len=.2  #windowlenth of sliding window in seconds\n",
    "par.w_mig = 4.\n",
    "par.win_frac=0.1 #step width of sliding window\n",
    "par.sll_x=-0.5 #lower bound of slowness s/km\n",
    "par.slm_x=0.5 #upper bound of slowness s/km\n",
    "par.sll_y=-0.5 #ditto but y axis\n",
    "par.slm_y=0.5 #ditto\n",
    "par.sl_s=0.025 #grid with for search area\n",
    "par.thres_rel = 0.0 #semblance value for trigger\n",
    "par.thres_slow = 0.6\n",
    "par.pre_trigger = 0.1\n",
    "par.sds_root = SDS_DATA_PATH\n",
    "par.phasefile = \"./RF_Richels/afewones.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(par)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced plotting comes now ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy import read_inventory, UTCDateTime\n",
    "import cartopy.crs as ccrs\n",
    "import csv\n",
    "\n",
    "from math import asin, atan2, cos, degrees, radians, sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for qiver\n",
    "def get_point_at_distance(lat1, lon1, d, bearing, R=6371):\n",
    "    \"\"\"\n",
    "    lat: initial latitude, in degrees\n",
    "    lon: initial longitude, in degrees\n",
    "    d: target distance from initial\n",
    "    bearing: (true) heading in degrees\n",
    "    R: optional radius of sphere, defaults to mean radius of earth\n",
    "\n",
    "    Returns new lat/lon coordinate {d}km from initial, in degrees\n",
    "    \"\"\"\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    a = radians(bearing)\n",
    "    lat2 = asin(sin(lat1) * cos(d/R) + cos(lat1) * sin(d/R) * cos(a))\n",
    "    lon2 = lon1 + atan2(\n",
    "        sin(a) * sin(d/R) * cos(lat1),\n",
    "        cos(d/R) - sin(lat1) * sin(lat2)\n",
    "    )\n",
    "    return (degrees(lat2), degrees(lon2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in topo data which was download via the Swiss topo\n",
    "#downloader of QGis and than exported to a shape file -\n",
    "#we load the stuff into cartopy\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io.shapereader import Reader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "\n",
    "shapefile = \"./shape/grenz.shp\"\n",
    "\n",
    "shape_feature = ShapelyFeature(Reader(shapefile).geometries(),\\\n",
    "                               ccrs.PlateCarree(), facecolor='none')\n",
    "#choosing a valid projection\n",
    "proj = ccrs.TransverseMercator(\n",
    "   central_latitude=45.9,\n",
    "   central_longitude=7.8)\n",
    "\n",
    "#restrict the plotting area\n",
    "min_lon = 7.8148\n",
    "max_lon = 7.87217\n",
    "min_lat = 45.9197\n",
    "max_lat = 45.9397\n",
    "\n",
    "\n",
    "directory = os.fsencode(par.output_path)\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".csv\"): \n",
    "        filetemp = filename[:-7]\n",
    "        csv_input= \"%s/%s\"%(par.output_path, filetemp)\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        ax = fig.add_subplot(projection=proj)\n",
    "        ax.add_feature(shape_feature)\n",
    "        ax.set_extent([min_lon,max_lon,min_lat,max_lat])\n",
    "\n",
    "\n",
    "        stations_f = []\n",
    "        inv = read_inventory(\"./stationxml/station_4D_A?P1.xml\")\n",
    "        for stat in inv:\n",
    "            stat_id =  stat.get_contents()['channels'][0]\n",
    "            coo = inv.get_coordinates(stat_id)\n",
    "            ll = [stat[0].code, coo['longitude'], coo['latitude'], coo['elevation']]\n",
    "            stations_f.append(ll)\n",
    "\n",
    "        for name, lon, lat, elev in stations_f:\n",
    "            ax.plot(lon,lat, \"rv\", markersize=5, transform=ccrs.PlateCarree())\n",
    "            try:\n",
    "                csvf = \"%s%s.csv\"%(csv_input,name[:-2])\n",
    "                baz = []\n",
    "                mcorr = []\n",
    "                slow = []\n",
    "                with open(csvf, 'r') as f:\n",
    "                    reader = csv.reader(f)\n",
    "                    for row in reader:\n",
    "                        baz.append(float(row[3]))\n",
    "                        mcorr.append(float(row[1]))\n",
    "                        slow.append(float(row[-1]))\n",
    "\n",
    "                baz = np.asarray(baz)\n",
    "                mcorr = np.asarray(mcorr)\n",
    "                slow = np.asarray(slow)\n",
    "                for i in range(len(baz)):\n",
    "                    if np.abs(mcorr[i]) > 0.7 and slow[i]<0.33:\n",
    "                        y,x = get_point_at_distance(lat, lon, 1, baz[i])\n",
    "                        dy = (y - lat)*10000\n",
    "                        dx = (x - lon)*10000\n",
    "                        dx = [lon,x]\n",
    "                        dy = [lat,y]\n",
    "                        ax.plot(dx,dy,\"g-\",alpha=np.abs(mcorr[i])/10,transform=ccrs.PlateCarree())\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        fig.savefig(\"%s/%s.png\"%(par.figure_path,filetemp), dpi=300)\n",
    "        plt.show()\n",
    "                                                                                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
